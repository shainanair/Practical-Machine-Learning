---
title: "PML Project"
author: "Shaina Nair"
date: "10/23/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(rpart)
library(rpart.plot)
library(rattle)
library(knitr)
library(randomForest)
library(RColorBrewer)
```



Downloading and reading the files.
```{r}
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
pmltraining <- read.csv(url(trainUrl),sep = ",", na.strings = c("", "NA"))
pmltesting <- read.csv(url(testUrl),sep = ",", na.strings = c("", "NA"))
```
Testing the files for my start point.
```{r}
dim(pmltraining)
dim(pmltesting)
```

Pre screening of variables with too many NA values
```{r}
training.nonNAs <- pmltraining[ , colSums(is.na(pmltraining)) == 0]
dim(training.nonNAs)
```

Cleaning my values

```{r}
cleanpmlTraining<-training.nonNAs[,-c(1:8)]
dim(cleanpmlTraining)
cleanpmltesting<-pmltesting[,names(cleanpmlTraining[,-52])]
dim(cleanpmltesting)
```

Partitioning the data to create a 75%  training set and a 25% test set.
```{r}
inTrain<-createDataPartition(y=cleanpmlTraining$classe, p=0.75,list=F)
training<-cleanpmlTraining[inTrain,] 
test<-cleanpmlTraining[-inTrain,]
dim(training)
```

Cross validation using a random forest done at 5 fold.This achieves 95% CI(0.9906,0.9954),Accuracy 99% and a kappa value of 0.992

```{r}
Modfit1<-trainControl(method="cv", number=5, allowParallel=T, verbose=T)
rffit<-train(classe~.,data=training, method="rf", trControl=Modfit1, verbose=F)
pred.rf<-predict(rffit, newdata=test)
confusionMatrix(pred.rf, test$classe)
pred.20<-predict(rffit, newdata=cleanpmltesting)
pred.20
```

using Fancy rpart plot
```{r}
set.seed(1234)
modFit2 <- rpart(classe ~ ., data=cleanpmlTraining, method="class")
print(modFit2)
fancyRpartPlot(modFit2, digits=2)
```
